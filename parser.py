import requests
from bs4 import BeautifulSoup
from config import ITPROGER_URL, HEADERS
import re


class ITProgerParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(HEADERS)

    def get_articles(self, page=1):
        """–ü–∞—Ä—Å–∏—Ç —Å—Ç–∞—Ç—å–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            url = f"{ITPROGER_URL}/{page}" if page > 1 else ITPROGER_URL
            print(f"üîÑ –ü–∞—Ä—Å–∏–Ω–≥ URL: {url}")
            response = self.session.get(url, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')
            articles = []

            # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π - –∏—â–µ–º –ª—é–±—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏ —Å —Å—Å—ã–ª–∫–∞–º–∏
            article_blocks = soup.find_all('a', href=True)

            for block in article_blocks:
                if len(articles) >= 5:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 5 —Å—Ç–∞—Ç—å—è–º–∏
                    break

                href = block['href']
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ç—å–∏
                if '/news/' in href and href != '/news/':
                    article = self._parse_article_block(block)
                    if article and article['title'] and article['title'] != "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞":
                        articles.append(article)

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å—Ç–∞—Ç–µ–π, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
            if not articles:
                articles = self._alternative_parse(soup)

            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(articles)}")
            return articles

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return []

    def _parse_article_block(self, block):
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫ —Å—Ç–∞—Ç—å–∏"""
        try:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title_elem = (block.find('h2') or
                          block.find('h3') or
                          block.find('h1') or
                          block.find('span') or
                          block)
            title = title_elem.get_text().strip() if title_elem else "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"

            # –°—Å—ã–ª–∫–∞
            link = block['href']
            if link and not link.startswith('http'):
                link = f"https://itproger.com{link}" if link.startswith('/') else f"https://itproger.com/{link}"

            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_elem = block.find('img')
            img_url = img_elem.get('src') if img_elem else ""
            if img_url and not img_url.startswith('http'):
                img_url = f"https://itproger.com{img_url}" if img_url.startswith('/') else img_url

            # –û–ø–∏—Å–∞–Ω–∏–µ (–∏—â–µ–º –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ)
            parent = block.parent
            desc_elem = (parent.find('p') if parent else None)
            description = desc_elem.get_text().strip() if desc_elem else "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"

            # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            if len(description) > 200:
                description = description[:200] + "..."

            # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if len(title) > 100:
                title = title[:100] + "..."

            return {
                'title': title,
                'description': description,
                'image_url': img_url,
                'link': link,
                'full_content': None
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –±–ª–æ–∫–∞: {e}")
            return None

    def _alternative_parse(self, soup):
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        articles = []
        try:
            # –ò—â–µ–º –ø–æ –∫–ª–∞—Å—Å–∞–º
            for elem in soup.find_all(class_=True):
                class_names = ' '.join(elem.get('class', []))
                if any(word in class_names.lower() for word in ['article', 'news', 'post', 'card']):
                    title_elem = elem.find(['h1', 'h2', 'h3', 'h4'])
                    link_elem = elem.find('a', href=True)

                    if title_elem and link_elem:
                        title = title_elem.get_text().strip()
                        link = link_elem['href']

                        if link and not link.startswith('http'):
                            link = f"https://itproger.com{link}" if link.startswith(
                                '/') else f"https://itproger.com/{link}"

                        articles.append({
                            'title': title,
                            'description': "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ",
                            'image_url': "",
                            'link': link,
                            'full_content': None
                        })

                        if len(articles) >= 5:
                            break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")

        return articles

    def get_full_content(self, article_url):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç–∞—Ç—å–∏"""
        try:
            response = self.session.get(article_url, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')

            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
            content_elem = (soup.find('article') or
                            soup.find('div', class_=re.compile(r'content|post-content|article-content')) or
                            soup.find('main'))

            if content_elem:
                # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                for elem in content_elem.find_all(['script', 'style', 'nav', 'footer', 'header']):
                    elem.decompose()

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–¥ –±–ª–æ–∫–∏ –¥–ª—è Markdown
                for code_block in content_elem.find_all('pre'):
                    code_block.replace_with(f"\n```\n{code_block.get_text()}\n```\n")

                text = content_elem.get_text().strip()
                return text[:2000] + "..." if len(text) > 2000 else text
            else:
                return "–ü–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç–∞—Ç—å–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç–∞—Ç—å–∏"